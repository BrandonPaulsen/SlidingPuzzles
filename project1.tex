\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage,amsmath,hyperref,indentfirst,graphicx,wrapfig,caption,subcaption}
\graphicspath{{~/Desktop/JUPYTER-LAB}}
\date{}
\begin{document}
{\LARGE{\hskip 2.2 in CS170 Project 1}}
\vskip 0.5in
{\flushleft{Brandon Paulsen}}
{\flushleft{October 31$^\text{st}$, 2022}}
{\flushleft{UCR CS170 Fall 2022}}
{\flushleft{Professor Eamonn Keough}}
\vskip 0.5in
\tableofcontents
\listoffigures
\pagebreak
\section{Introduction}
In this project, we are asked to write a program that uses a general search algorithm (A*) to solve 8 puzzles. An 8 puzzle is a puzzle that has 8 tiles arranged in a 3x3 grid, with one space. The goal of the puzzle is to arrange the tiles such that the first row is [1,2,3], the second row is [4,5,6], and the last row is [7,8,empty] by moving tiles around. Tiles next to the empty tile can swap places with the empty tile, or we can understand this as the empty tile swapping with tiles next to it.
\par A* is a search agorithm that uses both the depth of a state and a heuristic function to gague which unexplored states in the frontier should be explored first. It does this by assigning each state in the frontier a priority that is equal to the sum of the depth and heuristic, and as long as the heuristic is admissible (that is, it never overestimates the number of moves from the state to the goal state), A* will be optimal. In this project, we are tasked with implementing 3 heuristic functions: Uniform Cost, Misplaced Tiles, and Manhattan Distance.
\par As has been discussed in class multiple times, the branching factor and diameter of a search problem are very important. In fact, the branching factor and the problem diameter of a search problem define the magnitude of the search space, so it might be good to investigate them a little bit. Based on the loose idea that the branching factor is the average of the number of valid moves of a state, we can approximate the branching factor as $4\cdot\frac{1}{9}+3\cdot\frac{4}{9}+2\cdot\frac{4}{9} = \frac{24}{9} \approx 2.6$, because there are 4 corner spaces with 2 moves, 4 edge spaces with 3 moves, and 1 center space with 4 moves. This seems reasonable, but if we further consider that we cannot go back to any states previously visited, and at least one move for each state goes back to a previous state, we can reduce the approximate branching factor to $3\cdot\frac{1}{9}+2\cdot\frac{4}{9}+1\cdot\frac{4}{9} = \frac{15}{9} \approx 1.7$. This is a very small branching factor, which is great news for us. We can further extend this approximation of the branching factor to any n puzzle as $\frac{4}{n^2}+\frac{8\cdot(n-2)}{n^2}+\frac{3\cdot(n^2-4\cdot(n-2)-4)}{n^2} = 3-\frac{4}{n}$.
\par
\section{Heuristics}
Heuristics are a the heart of the A* algorithm, without them, A* would be no better than breadth first search. As such, it is important to discuss the heuristics used in this project both in terms of their implementation and their impact on space and time complexity.
\subsection{Uniform Cost}
Uniform Cost Heuristic is the simplest of the 3 heuristics. It simply evaluates to 0 for all states. This means that in effect, A* with Uniform Cost Heuristic devolves to breadth first search and searches level-by-level.
\subsection{Misplaced Tile}
Misplaced Tile Heuristic, though slightly more complex than Uniform Cost Heuristic (which is trivial), is not overly complex. Evaluating the Misplaced Tile Heuristic of a state amounts to counting up the number of tiles in a given state that are not in the same position as they are in the goal state. Though it is much better than Uniform Cost Heuristic, it is clearly not the best heuristic, as children of a state (those states that are reachable from that state in a move) often are assigned the same priority, and therefore the search algorithm has a hard time distinguishing which is better and should be explored first.
\subsection{Manhattan Distance}
Though Manhattan Distance Heuristic is the most complex of the 3, it offers some potential benefits that warrant its use. In all cases, Manhattan Distance Heuristic dominates Misplaced Tile Heuristic - that is to say, its value is greater than Misplaced Tile Hueristic without overestimating the number of moves left and therefore destroying the optimality of the A* algorithm. The Manhattan Distance Heuristic is calculated by totaling the differences in x and y positions of tiles between a given state and the goal state, or in math terms, $\sum_{\text{tiles}\neq\text{empty}}\Delta x + \Delta y$. Though Manhattan Distance Heuristic is admissible, it is clearly not perfect, and there is still room for improvement.
\section{Test Cases}
Many test cases were given in the project assignment. They range from trivial (depth 0) to very complex (depth 24) and make for good tests of algorithms. For a significant portion of time, my implementation of the general search algorithm when used with Manhattan Distance Heuristic failed to find the most optimal path (the path it found was at depth 26). This was very helpful to me in that it indicated an error in my code.
\section{Monte Carlo Simulation}
I ran a monte carlo simulation with 100,000 trials to get some idea of how the number of visited nodes, frontier nodes, and search time changed with depth for each heuristic. Running 100,000 trials of Manhattan Distance search is unfeasible in python, let alone uniform cost, so I wrote the monte carlo simulation in my C++ implementation. Overall, the trials took something like a few hours to run the simulation, most of which was due to the uniform cost search, but it was well worth it to satisfy my curiousity.  For each heuristic, I recorded the number of visited states, number of frontier states at the time of finding the goal state (though there may have been more goal states previously), and the amount of time that the search took, all as an average per depth.
\subsection{Uniform Cost}
\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{uniformCostVisited.png}
		\caption{Visited Nodes vs Depth}
		\label{fig:Uniform Cost Visited Nodes}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{uniformCostFrontier.png}
		\caption{Frontier Nodes vs Depth}
		\label{fig:Uniform Cost Frontier Nodes}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{uniformCostTime.png}
		\caption{Search Time vs Depth}
		\label{fig:Uniform Cost Frontier Nodes}
	\end{subfigure}
	\caption{Uniform Cost Monte Carlo Simulation Results}
	\label{fig:Uniform Cost Monte Carlo Simulation}
\end{figure}
In these graphs, it can be seen that the number of visited nodes, the number of frontier nodes, and the search trime grow approximately exponentially (as should be expected), but taper off significantly as the depth nears the diameter of the problem. This is because, as we get closer and closer to the maximum possible depth, we have already explored most of the possible states of the puzle and there are less to explore, decreasing the branching factor quite significantly. If this were not the case, we would expect to see the exponential trend continue indefinitely.
\subsection{Misplaced Tile}
\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{misplacedTileVisited.png}
		\caption{Visited Nodes vs Depth}
		\label{fig:Misplaced Tile Visited Nodes}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{misplacedTileFrontier.png}
		\caption{Frontier Nodes vs Depth}
		\label{fig:Misplaced Tile Frontier Nodes}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{misplacedTileTime.png}
		\caption{Search Time vs Depth}
		\label{fig:Misplaced Tile Frontier Nodes}
	\end{subfigure}
	\caption{Misplaced Tile Monte Carlo Simulation Results}
	\label{fig:Misplaced Tile Monte Carlo Simulation}
\end{figure}
\subsection{Manhattan Distance}
\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{manhattanDistanceVisited.png}
		\caption{Visited Nodes vs Depth}
		\label{fig:Manhattan Distance Visited Nodes}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{manhattanDistanceFrontier.png}
		\caption{Frontier Nodes vs Depth}
		\label{fig:Manhattan Distance Frontier Nodes}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{manhattanDistanceTime.png}
		\caption{Search Time vs Depth}
		\label{fig:Manhattan Distance Frontier Nodes}
	\end{subfigure}
	\caption{Manhattan Distance Monte Carlo Simulation Results}
	\label{fig:Manhattan Distance Monte Carlo Simulation}
\end{figure}
\subsection{Trend Comparison}\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{visitedComparison.png}
		\caption{Visited Nodes vs Depth}
		\label{fig:Visited Nodes Comparison}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{frontierComparison.png}
		\caption{Frontier Nodes vs Depth}
		\label{fig:Frontier Comparison}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth]{timeComparison.png}
		\caption{Search Time vs Depth}
		\label{fig:Search Time Comparison}
	\end{subfigure}
	\caption{Monte Carlo Simulation Results Comparison}
	\label{fig:Monte Carlo Simulation Comparison}
\end{figure}
\section{Conclusion}
\section{Code}
\subsection{C++}
My C++ code can be found at \url{https://github.com/Poly1581/SlidingPuzzles}
\subsection{Python}
My python code can be found at \url{https://github.com/Poly1581/PYSlidingPuzzles}


\end{document}
